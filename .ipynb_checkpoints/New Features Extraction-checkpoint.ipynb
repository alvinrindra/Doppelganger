{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models8-100-w10-classifier.joblib.pkl',\n",
       " 'models17-100-w10-classifier.joblib.pkl',\n",
       " 'models32-100-w10-classifier.joblib.pkl',\n",
       " 'models7-100-w10-classifier.joblib.pkl',\n",
       " 'models18-100-w10-classifier.joblib.pkl',\n",
       " 'models23-100-w10-classifier.joblib.pkl',\n",
       " 'models10-100-w10-classifier.joblib.pkl',\n",
       " 'models35-100-w10-classifier.joblib.pkl',\n",
       " 'models0-100-w10-classifier.joblib.pkl',\n",
       " 'Part2',\n",
       " 'models24-100-w10-classifier.joblib.pkl',\n",
       " 'models22-100-w10-classifier.joblib.pkl',\n",
       " 'models6-100-w10-classifier.joblib.pkl',\n",
       " 'models19-100-w10-classifier.joblib.pkl',\n",
       " 'models33-100-w10-classifier.joblib.pkl',\n",
       " 'models9-100-w10-classifier.joblib.pkl',\n",
       " 'models16-100-w10-classifier.joblib.pkl',\n",
       " 'models25-100-w10-classifier.joblib.pkl',\n",
       " 'New__datasets.csv',\n",
       " 'models1-100-w10-classifier.joblib.pkl',\n",
       " 'models34-100-w10-classifier.joblib.pkl',\n",
       " 'models11-100-w10-classifier.joblib.pkl',\n",
       " 'README.md',\n",
       " 'models38-100-w10-classifier.joblib.pkl',\n",
       " 'models26-100-w10-classifier.joblib.pkl',\n",
       " 'models2-100-w10-classifier.joblib.pkl',\n",
       " 'models37-100-w10-classifier.joblib.pkl',\n",
       " 'models29-100-w10-classifier.joblib.pkl',\n",
       " 'models12-100-w10-classifier.joblib.pkl',\n",
       " 'New Features Extraction.ipynb',\n",
       " 'models21-100-w10-classifier.joblib.pkl',\n",
       " 'models41-100-w10-classifier.joblib.pkl',\n",
       " 'models5-100-w10-classifier.joblib.pkl',\n",
       " 'Part1',\n",
       " 'models30-100-w10-classifier.joblib.pkl',\n",
       " 'models15-100-w10-classifier.joblib.pkl',\n",
       " '.ipynb_checkpoints',\n",
       " 'Features.csv',\n",
       " 'models13-100-w10-classifier.joblib.pkl',\n",
       " 'Joined_1.csv',\n",
       " 'models36-100-w10-classifier.joblib.pkl',\n",
       " 'models28-100-w10-classifier.joblib.pkl',\n",
       " 'models3-100-w10-classifier.joblib.pkl',\n",
       " '.git',\n",
       " 'models39-100-w10-classifier.joblib.pkl',\n",
       " 'models27-100-w10-classifier.joblib.pkl',\n",
       " 'models14-100-w10-classifier.joblib.pkl',\n",
       " 'models31-100-w10-classifier.joblib.pkl',\n",
       " 'models40-100-w10-classifier.joblib.pkl',\n",
       " 'models4-100-w10-classifier.joblib.pkl',\n",
       " 'models20-100-w10-classifier.joblib.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir('C:/Users/Alvin F/Downloads/Practical_sheet2_submission/Practical_sheet2_submission/source_code')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_csv('Joined_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>total words per comment</th>\n",
       "      <th>frequency of large words per comment</th>\n",
       "      <th>Simpson</th>\n",
       "      <th>Sichel</th>\n",
       "      <th>Average sentence length per comment</th>\n",
       "      <th>Frequency of used punctuation per comment</th>\n",
       "      <th>Frequency of repeated occurrence of whitespace per comment</th>\n",
       "      <th>Number of grammar mistakes per comment</th>\n",
       "      <th>Uppercase word usage per comment</th>\n",
       "      <th>Ease reading for the content</th>\n",
       "      <th>Gunning Fog value for the content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>*ff einem in Frankfurt(Main) er wil gern wiede...</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070024</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>80.400000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>65.40</td>\n",
       "      <td>13.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>\"Die EU stellt seit 2011 Öllieferungen an Syri...</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>50.55</td>\n",
       "      <td>16.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>\"Die Evangelikalen haben aber auch mit der bib...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>110.571429</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>47.30</td>\n",
       "      <td>16.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>\"Die Testkapazitäten liegen bei 964.000 Tests,...</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>63.30</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>\"Duester\" ist ganz schoen polemisch. Japan bra...</td>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>34.30</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>3927</td>\n",
       "      <td>3927</td>\n",
       "      <td>3927</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>Das Problem ist vielschichtiger. Ich weiß beis...</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>48.05</td>\n",
       "      <td>18.54</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>3926</td>\n",
       "      <td>3926</td>\n",
       "      <td>3926</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>Das liegt auch daran, dass diese Personengrupp...</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>43.85</td>\n",
       "      <td>18.80</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>3925</td>\n",
       "      <td>3925</td>\n",
       "      <td>3925</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>Das ist falsch. Eine Kündigung bedarf nur der ...</td>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>0.067137</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>50.40</td>\n",
       "      <td>13.36</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>3935</td>\n",
       "      <td>3935</td>\n",
       "      <td>3935</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>Die Antwort ist ganz einfach. Facebook unterli...</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>0.068521</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.20</td>\n",
       "      <td>13.62</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3999</td>\n",
       "      <td>3999</td>\n",
       "      <td>3999</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>Terroristen und Kriminelle haben nur so viel M...</td>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>114.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>52.15</td>\n",
       "      <td>13.88</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1     username  \\\n",
       "249          249           249             249   Ariovistvs   \n",
       "223          223           223             223   Ariovistvs   \n",
       "224          224           224             224   Ariovistvs   \n",
       "225          225           225             225   Ariovistvs   \n",
       "226          226           226             226   Ariovistvs   \n",
       "...          ...           ...             ...          ...   \n",
       "3927        3927          3927            3927  zelebration   \n",
       "3926        3926          3926            3926  zelebration   \n",
       "3925        3925          3925            3925  zelebration   \n",
       "3935        3935          3935            3935  zelebration   \n",
       "3999        3999          3999            3999  zelebration   \n",
       "\n",
       "                                                content  \\\n",
       "249   *ff einem in Frankfurt(Main) er wil gern wiede...   \n",
       "223   \"Die EU stellt seit 2011 Öllieferungen an Syri...   \n",
       "224   \"Die Evangelikalen haben aber auch mit der bib...   \n",
       "225   \"Die Testkapazitäten liegen bei 964.000 Tests,...   \n",
       "226   \"Duester\" ist ganz schoen polemisch. Japan bra...   \n",
       "...                                                 ...   \n",
       "3927  Das Problem ist vielschichtiger. Ich weiß beis...   \n",
       "3926  Das liegt auch daran, dass diese Personengrupp...   \n",
       "3925  Das ist falsch. Eine Kündigung bedarf nur der ...   \n",
       "3935  Die Antwort ist ganz einfach. Facebook unterli...   \n",
       "3999  Terroristen und Kriminelle haben nur so viel M...   \n",
       "\n",
       "      total words per comment  frequency of large words per comment   Simpson  \\\n",
       "249                        65                                     5  0.070024   \n",
       "223                        55                                    13  0.060605   \n",
       "224                       110                                    23  0.060034   \n",
       "225                        57                                    13  0.059210   \n",
       "226                        68                                    14  0.066124   \n",
       "...                       ...                                   ...       ...   \n",
       "3927                       65                                     6  0.069514   \n",
       "3926                       50                                     6  0.066899   \n",
       "3925                      101                                    14  0.067137   \n",
       "3935                       87                                    15  0.068521   \n",
       "3999                      101                                    10  0.066712   \n",
       "\n",
       "        Sichel  Average sentence length per comment  \\\n",
       "249   0.012315                            80.400000   \n",
       "223   0.012658                           131.000000   \n",
       "224   0.007692                           110.571429   \n",
       "225   0.009828                            80.600000   \n",
       "226   0.005803                           128.500000   \n",
       "...        ...                                  ...   \n",
       "3927  0.012469                           200.000000   \n",
       "3926  0.014409                           347.000000   \n",
       "3925  0.005442                            91.000000   \n",
       "3935  0.003231                           102.333333   \n",
       "3999  0.011544                           114.666667   \n",
       "\n",
       "      Frequency of used punctuation per comment  \\\n",
       "249                                          13   \n",
       "223                                           8   \n",
       "224                                          18   \n",
       "225                                          20   \n",
       "226                                           8   \n",
       "...                                         ...   \n",
       "3927                                         12   \n",
       "3926                                         11   \n",
       "3925                                         22   \n",
       "3935                                         17   \n",
       "3999                                         25   \n",
       "\n",
       "      Frequency of repeated occurrence of whitespace per comment  \\\n",
       "249                                                   0            \n",
       "223                                                   0            \n",
       "224                                                   0            \n",
       "225                                                   0            \n",
       "226                                                   0            \n",
       "...                                                 ...            \n",
       "3927                                                  0            \n",
       "3926                                                  0            \n",
       "3925                                                  0            \n",
       "3935                                                  0            \n",
       "3999                                                  0            \n",
       "\n",
       "      Number of grammar mistakes per comment  \\\n",
       "249                                        2   \n",
       "223                                        0   \n",
       "224                                        0   \n",
       "225                                        0   \n",
       "226                                        0   \n",
       "...                                      ...   \n",
       "3927                                       0   \n",
       "3926                                       3   \n",
       "3925                                       2   \n",
       "3935                                       3   \n",
       "3999                                       4   \n",
       "\n",
       "      Uppercase word usage per comment  Ease reading for the content  \\\n",
       "249                                 16                         65.40   \n",
       "223                                 19                         50.55   \n",
       "224                                 31                         47.30   \n",
       "225                                 19                         63.30   \n",
       "226                                 23                         34.30   \n",
       "...                                ...                           ...   \n",
       "3927                                18                         48.05   \n",
       "3926                                11                         43.85   \n",
       "3925                                31                         50.40   \n",
       "3935                                22                         60.20   \n",
       "3999                                40                         52.15   \n",
       "\n",
       "      Gunning Fog value for the content  Label  \n",
       "249                               13.48      0  \n",
       "223                               16.77      0  \n",
       "224                               16.83      0  \n",
       "225                               14.38      0  \n",
       "226                               19.15      0  \n",
       "...                                 ...    ...  \n",
       "3927                              18.54     41  \n",
       "3926                              18.80     41  \n",
       "3925                              13.36     41  \n",
       "3935                              13.62     41  \n",
       "3999                              13.88     41  \n",
       "\n",
       "[4000 rows x 17 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = new.sort_values(by=['Label'])\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 11)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datdrop = new.drop(['Unnamed: 0','Unnamed: 0.1' ,'Unnamed: 0.1.1','username', 'content', 'Label'], axis = 1)\n",
    "datdrop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total words per comment</th>\n",
       "      <th>frequency of large words per comment</th>\n",
       "      <th>Simpson</th>\n",
       "      <th>Sichel</th>\n",
       "      <th>Average sentence length per comment</th>\n",
       "      <th>Frequency of used punctuation per comment</th>\n",
       "      <th>Frequency of repeated occurrence of whitespace per comment</th>\n",
       "      <th>Number of grammar mistakes per comment</th>\n",
       "      <th>Uppercase word usage per comment</th>\n",
       "      <th>Ease reading for the content</th>\n",
       "      <th>Gunning Fog value for the content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>0.070024</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>80.400000</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>65.40</td>\n",
       "      <td>13.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>0.060605</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>50.55</td>\n",
       "      <td>16.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>110.571429</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>47.30</td>\n",
       "      <td>16.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>63.30</td>\n",
       "      <td>14.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>68</td>\n",
       "      <td>14</td>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>34.30</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>0.012469</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>48.05</td>\n",
       "      <td>18.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>347.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>43.85</td>\n",
       "      <td>18.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>101</td>\n",
       "      <td>14</td>\n",
       "      <td>0.067137</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>50.40</td>\n",
       "      <td>13.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>0.068521</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>60.20</td>\n",
       "      <td>13.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>114.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>52.15</td>\n",
       "      <td>13.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total words per comment  frequency of large words per comment   Simpson  \\\n",
       "249                        65                                     5  0.070024   \n",
       "223                        55                                    13  0.060605   \n",
       "224                       110                                    23  0.060034   \n",
       "225                        57                                    13  0.059210   \n",
       "226                        68                                    14  0.066124   \n",
       "...                       ...                                   ...       ...   \n",
       "3927                       65                                     6  0.069514   \n",
       "3926                       50                                     6  0.066899   \n",
       "3925                      101                                    14  0.067137   \n",
       "3935                       87                                    15  0.068521   \n",
       "3999                      101                                    10  0.066712   \n",
       "\n",
       "        Sichel  Average sentence length per comment  \\\n",
       "249   0.012315                            80.400000   \n",
       "223   0.012658                           131.000000   \n",
       "224   0.007692                           110.571429   \n",
       "225   0.009828                            80.600000   \n",
       "226   0.005803                           128.500000   \n",
       "...        ...                                  ...   \n",
       "3927  0.012469                           200.000000   \n",
       "3926  0.014409                           347.000000   \n",
       "3925  0.005442                            91.000000   \n",
       "3935  0.003231                           102.333333   \n",
       "3999  0.011544                           114.666667   \n",
       "\n",
       "      Frequency of used punctuation per comment  \\\n",
       "249                                          13   \n",
       "223                                           8   \n",
       "224                                          18   \n",
       "225                                          20   \n",
       "226                                           8   \n",
       "...                                         ...   \n",
       "3927                                         12   \n",
       "3926                                         11   \n",
       "3925                                         22   \n",
       "3935                                         17   \n",
       "3999                                         25   \n",
       "\n",
       "      Frequency of repeated occurrence of whitespace per comment  \\\n",
       "249                                                   0            \n",
       "223                                                   0            \n",
       "224                                                   0            \n",
       "225                                                   0            \n",
       "226                                                   0            \n",
       "...                                                 ...            \n",
       "3927                                                  0            \n",
       "3926                                                  0            \n",
       "3925                                                  0            \n",
       "3935                                                  0            \n",
       "3999                                                  0            \n",
       "\n",
       "      Number of grammar mistakes per comment  \\\n",
       "249                                        2   \n",
       "223                                        0   \n",
       "224                                        0   \n",
       "225                                        0   \n",
       "226                                        0   \n",
       "...                                      ...   \n",
       "3927                                       0   \n",
       "3926                                       3   \n",
       "3925                                       2   \n",
       "3935                                       3   \n",
       "3999                                       4   \n",
       "\n",
       "      Uppercase word usage per comment  Ease reading for the content  \\\n",
       "249                                 16                         65.40   \n",
       "223                                 19                         50.55   \n",
       "224                                 31                         47.30   \n",
       "225                                 19                         63.30   \n",
       "226                                 23                         34.30   \n",
       "...                                ...                           ...   \n",
       "3927                                18                         48.05   \n",
       "3926                                11                         43.85   \n",
       "3925                                31                         50.40   \n",
       "3935                                22                         60.20   \n",
       "3999                                40                         52.15   \n",
       "\n",
       "      Gunning Fog value for the content  \n",
       "249                               13.48  \n",
       "223                               16.77  \n",
       "224                               16.83  \n",
       "225                               14.38  \n",
       "226                               19.15  \n",
       "...                                 ...  \n",
       "3927                              18.54  \n",
       "3926                              18.80  \n",
       "3925                              13.36  \n",
       "3935                              13.62  \n",
       "3999                              13.88  \n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datdrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leute von heute                            100\n",
       "rock_lobster                               100\n",
       "Ariovistvs                                 100\n",
       "R.B.C.                                     100\n",
       "Friwi                                      100\n",
       "cedebe                                     100\n",
       "margherita                                 100\n",
       "alpinist                                   100\n",
       "Gamma Ray Burst                            100\n",
       "Peter Pekster                              100\n",
       "Yankee Babe                                100\n",
       "Hans_Joachim                               100\n",
       "CETAoderGoodByeGermany                     100\n",
       "aaaaaaaaaaaaaaaasssssssssssssdddddddddd    100\n",
       "Jan Reiter                                 100\n",
       "sonnenkatze                                100\n",
       "zelebration                                100\n",
       "diespdisttot                               100\n",
       "eagle58                                    100\n",
       "knowwhereman                               100\n",
       "deep_franz                                 100\n",
       "Lucy Meineke                               100\n",
       "Maik12                                     100\n",
       "Mahlsdorfer                                100\n",
       "too late                                   100\n",
       "Ribald Corello                             100\n",
       "no-panic                                   100\n",
       "Zeit 12                                    100\n",
       "Jordanes                                   100\n",
       "slocum                                     100\n",
       "Eckard P.                                  100\n",
       "Sumtina                                    100\n",
       "Lea Paul                                   100\n",
       "JuJuMila                                   100\n",
       "Bleiben Sie sachlich                       100\n",
       "globallynaive                              100\n",
       "Richi Rich                                 100\n",
       "gottwuerfeltnicht                          100\n",
       "Superforecaster                             99\n",
       "whitemouse-neu                              87\n",
       "whitemouse                                  13\n",
       "Super-Duper Missile                          1\n",
       "Name: username, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[\"username\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 65.00,  5.00,  0.07, ...,  16.00,  65.40,  13.48],\n",
       "       [ 55.00,  13.00,  0.06, ...,  19.00,  50.55,  16.77],\n",
       "       [ 110.00,  23.00,  0.06, ...,  31.00,  47.30,  16.83],\n",
       "       ...,\n",
       "       [ 101.00,  14.00,  0.07, ...,  31.00,  50.40,  13.36],\n",
       "       [ 87.00,  15.00,  0.07, ...,  22.00,  60.20,  13.62],\n",
       "       [ 101.00,  10.00,  0.07, ...,  40.00,  52.15,  13.88]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
    "dat_array = datdrop.to_numpy()\n",
    "dat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "dat_standardized = scaler.fit_transform(dat_array)\n",
    "dat_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COVMAT = np.cov(dat_standardized.T)\n",
    "COVMAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(COVMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.26,  2.29,  1.20,  1.12,  0.70,  0.53,  0.40,  0.05,  0.10,\n",
       "        0.14,  0.22])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.width = 0\n",
    "pca = PCA(n_components = 0.999)\n",
    "# pca = PCA()\n",
    "DATA_PCA = pca.fit_transform(dat_array)\n",
    "DATA_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29.799725</td>\n",
       "      <td>16.071004</td>\n",
       "      <td>-5.838649</td>\n",
       "      <td>-0.417293</td>\n",
       "      <td>3.383473</td>\n",
       "      <td>0.325130</td>\n",
       "      <td>-1.026253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.661715</td>\n",
       "      <td>40.747213</td>\n",
       "      <td>0.160617</td>\n",
       "      <td>-4.216903</td>\n",
       "      <td>-4.383876</td>\n",
       "      <td>-4.102117</td>\n",
       "      <td>0.317150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.534741</td>\n",
       "      <td>-20.283757</td>\n",
       "      <td>6.673329</td>\n",
       "      <td>-7.548071</td>\n",
       "      <td>-1.662134</td>\n",
       "      <td>-7.180570</td>\n",
       "      <td>-0.816202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-30.463414</td>\n",
       "      <td>20.512249</td>\n",
       "      <td>-0.668826</td>\n",
       "      <td>6.132401</td>\n",
       "      <td>-2.709319</td>\n",
       "      <td>-7.737658</td>\n",
       "      <td>-1.515192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.797114</td>\n",
       "      <td>28.146186</td>\n",
       "      <td>15.548316</td>\n",
       "      <td>-8.437739</td>\n",
       "      <td>-3.159256</td>\n",
       "      <td>-0.242113</td>\n",
       "      <td>-1.345525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>84.895860</td>\n",
       "      <td>53.600669</td>\n",
       "      <td>-13.174751</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>-0.510281</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>-3.642106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>217.155871</td>\n",
       "      <td>114.388127</td>\n",
       "      <td>-38.563391</td>\n",
       "      <td>6.690901</td>\n",
       "      <td>-1.644145</td>\n",
       "      <td>-2.866374</td>\n",
       "      <td>-0.312772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-4.376473</td>\n",
       "      <td>-18.358091</td>\n",
       "      <td>6.554218</td>\n",
       "      <td>-0.446928</td>\n",
       "      <td>-1.350157</td>\n",
       "      <td>-0.541807</td>\n",
       "      <td>-2.516509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>-0.689747</td>\n",
       "      <td>0.152609</td>\n",
       "      <td>-4.459907</td>\n",
       "      <td>-1.515752</td>\n",
       "      <td>1.569689</td>\n",
       "      <td>-5.303125</td>\n",
       "      <td>1.253785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>17.874809</td>\n",
       "      <td>-13.574599</td>\n",
       "      <td>0.363085</td>\n",
       "      <td>5.018765</td>\n",
       "      <td>-8.786052</td>\n",
       "      <td>4.939226</td>\n",
       "      <td>-2.649038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1          2         3         4         5  \\\n",
       "0     -29.799725   16.071004  -5.838649 -0.417293  3.383473  0.325130   \n",
       "1      17.661715   40.747213   0.160617 -4.216903 -4.383876 -4.102117   \n",
       "2      17.534741  -20.283757   6.673329 -7.548071 -1.662134 -7.180570   \n",
       "3     -30.463414   20.512249  -0.668826  6.132401 -2.709319 -7.737658   \n",
       "4      22.797114   28.146186  15.548316 -8.437739 -3.159256 -0.242113   \n",
       "...          ...         ...        ...       ...       ...       ...   \n",
       "3995   84.895860   53.600669 -13.174751  0.005041 -0.510281  0.760394   \n",
       "3996  217.155871  114.388127 -38.563391  6.690901 -1.644145 -2.866374   \n",
       "3997   -4.376473  -18.358091   6.554218 -0.446928 -1.350157 -0.541807   \n",
       "3998   -0.689747    0.152609  -4.459907 -1.515752  1.569689 -5.303125   \n",
       "3999   17.874809  -13.574599   0.363085  5.018765 -8.786052  4.939226   \n",
       "\n",
       "             6  \n",
       "0    -1.026253  \n",
       "1     0.317150  \n",
       "2    -0.816202  \n",
       "3    -1.515192  \n",
       "4    -1.345525  \n",
       "...        ...  \n",
       "3995 -3.642106  \n",
       "3996 -0.312772  \n",
       "3997 -2.516509  \n",
       "3998  1.253785  \n",
       "3999 -2.649038  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datfr = pd.DataFrame(DATA_PCA)\n",
    "datfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = datfr.to_numpy()\n",
    "y = new['Label'].to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4003"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_per_author = [[0]*(len(y)+3) for i in range(len(y)+3)]\n",
    "len(prob_per_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "# from sklearn import grid_search\n",
    "from sklearn.decomposition import PCA # ProbabilisticPCA\n",
    "from joblib import Parallel, delayed\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ariovistvs': 0,\n",
       " 'Bleiben Sie sachlich': 1,\n",
       " 'CETAoderGoodByeGermany': 2,\n",
       " 'Eckard P.': 3,\n",
       " 'Friwi': 4,\n",
       " 'Gamma Ray Burst': 5,\n",
       " 'Hans_Joachim': 6,\n",
       " 'Jan Reiter': 7,\n",
       " 'Jordanes': 8,\n",
       " 'JuJuMila': 9,\n",
       " 'Lea Paul': 10,\n",
       " 'Leute von heute': 11,\n",
       " 'Lucy Meineke': 12,\n",
       " 'Mahlsdorfer': 13,\n",
       " 'Maik12': 14,\n",
       " 'Peter Pekster': 15,\n",
       " 'R.B.C.': 16,\n",
       " 'Ribald Corello': 17,\n",
       " 'Richi Rich': 18,\n",
       " 'Sumtina': 19,\n",
       " 'Super-Duper Missile': 20,\n",
       " 'Superforecaster': 21,\n",
       " 'Yankee Babe': 22,\n",
       " 'Zeit 12': 23,\n",
       " 'aaaaaaaaaaaaaaaasssssssssssssdddddddddd': 24,\n",
       " 'alpinist': 25,\n",
       " 'cedebe': 26,\n",
       " 'deep_franz': 27,\n",
       " 'diespdisttot': 28,\n",
       " 'eagle58': 29,\n",
       " 'globallynaive': 30,\n",
       " 'gottwuerfeltnicht': 31,\n",
       " 'knowwhereman': 32,\n",
       " 'margherita': 33,\n",
       " 'no-panic': 34,\n",
       " 'rock_lobster': 35,\n",
       " 'slocum': 36,\n",
       " 'sonnenkatze': 37,\n",
       " 'too late': 38,\n",
       " 'whitemouse': 39,\n",
       " 'whitemouse-neu': 40,\n",
       " 'zelebration': 41}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_to_num = pd.Series(new[\"Label\"].values,index=new.username).to_dict()\n",
    "authors_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors:  42\n",
      "Authors are:  dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "encode_to_num = pd.Series(new[\"Label\"].values, new[\"Label\"].values).to_dict()\n",
    "print ('Total authors: ', len(encode_to_num.keys()))\n",
    "print ('Authors are: ', encode_to_num.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allAuthors = encode_to_num.keys()\n",
    "allAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import code\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbsGSThread(nthread, clf, data, label, allAuthors, modeldir, saveModel):\n",
    "            \n",
    "    lolo = LeaveOneGroupOut()\n",
    "    \n",
    "    lolo.get_n_splits(groups=label)\n",
    "\n",
    "    prob_per_author = [[0]*(len(allAuthors)+3) for i in range(len(allAuthors)+3)]\n",
    "    #print(prob_per_author)\n",
    "\n",
    "    scores = Parallel(n_jobs=nthread, verbose=5)(delayed(getProbsTrainTest)(clf, data, label, train, test, modeldir, saveModel) for train,test in lolo.split(data, label, groups=label))\n",
    "\n",
    "    #print(np.array(scores).shape)\n",
    "    for train, test in lolo.split(data, label, groups=label):\n",
    "\n",
    "        anAuthor = int(label[test[0]])\n",
    "        #print (anAuthor)\n",
    "        train_data_label = label[train]\n",
    "        trainAuthors = list(set(train_data_label))\n",
    "        test_data_label = label[test]\n",
    "        nTestDoc = len(scores)# len(test_data_label)\n",
    "        #print(nTestDoc)\n",
    "        for j in range(nTestDoc):\n",
    "            for i in range(len(trainAuthors)):\n",
    "                #code.interact(local=dict(globals(), **locals()))\n",
    "                try:\n",
    "                    prob_per_author[anAuthor][int(trainAuthors[i])] += scores[anAuthor-1][j][i]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                #x[i+1] = x[i] + ( t[i+1] - t[i] ) * f( x[i], t[i] ) by x.append(x[i] + ( t[i+1] - t[i] ) * f( x[i], t[i] ))\n",
    "\n",
    "        for i in range(len(trainAuthors)):\n",
    "            prob_per_author[anAuthor][int(trainAuthors[i])]/=nTestDoc\n",
    "    return prob_per_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "       Calculate all probabilities\n",
    "'''\n",
    "def getProbsTrainTest(clf, data, label, train, test, modeldir, saveModel):\n",
    "       \n",
    "        anAuthor = int(label[test[0]])\n",
    "        \n",
    "        print (\"current author \", anAuthor)\n",
    "        \n",
    "        train_data = data[train,:]\n",
    "        train_data_label = label[train]\n",
    "    \n",
    "        #test on anAuthor\n",
    "        test_data = data[test,:]\n",
    "        \n",
    "        #check if we already have a model\n",
    "        modelFile = modeldir+ str(anAuthor)+\"-\"+ saveModel\n",
    "        \n",
    "        if os.path.exists(modelFile):\n",
    "            clf = joblib.load(modelFile)\n",
    "        else:\n",
    "             #use the following two lines if you want to choose the regularization parameters using grid search\n",
    "            #parameters = {'C':[1, 10]}\n",
    "            #clf = grid_search.GridSearchCV(clf, parameters)\n",
    "            \n",
    "            #train\n",
    "            clf.fit(train_data, train_data_label)\n",
    "            \n",
    "            #save model\n",
    "            joblib.dump(clf, modelFile, compress=9)\n",
    "            print (\"model saved: \", modelFile)\n",
    "            \n",
    "        #get probabilities\n",
    "        scores = clf.predict_proba(test_data)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCombinedProbs(outfile, prob_per_author, allAuthors, encode_to_num, authors_name):\n",
    "        total_prob = {}\n",
    "        add_prob = {}\n",
    "        sq_prob = {}\n",
    "        \n",
    "        with open(outfile, \"w+\") as out:\n",
    "            out.write('Author 1, Author 2, P(1->2), P(2->1),P(1->2)*P(2->1),(P(1->2)+P(2->1))/2, (P(1->2)^2+P(2->1)^2)/2, Encode 1, Encode 2\\n')\n",
    "            for i in range(len(allAuthors)):\n",
    "                \n",
    "                    a = int(allAuthors[i])\n",
    "                    #if len(authors_to_numbers[a])==0:\n",
    "                    #    continue\n",
    "                    for j in range(i+1, len(allAuthors)):\n",
    "                        b = allAuthors[j]\n",
    "                        \n",
    "                        result = 0\n",
    "                        \n",
    "                        total = prob_per_author[a][b]*prob_per_author[b][a]\n",
    "                        addition = (prob_per_author[a][b]+prob_per_author[b][a])/2\n",
    "                        sqsum = (prob_per_author[a][b]*prob_per_author[a][b]+prob_per_author[b][a]*prob_per_author[b][a])/2\n",
    "                        \n",
    "                        out.write(str(authors_name[a])+\" ,\"+str(authors_name[b])+\" ,\"+\n",
    "                                  str(prob_per_author[a][b])+\",\"+str(prob_per_author[b][a])+\",\"+\n",
    "                                  str(total)+\",\"+str(addition)+\",\"+str(sqsum)+\",\"+\n",
    "                                  str(encode_to_num[a])+\" ,\"+str(encode_to_num[b])+\n",
    "                                  \"\\n\")\n",
    "                        \n",
    "                        #out.write(str(encode_to_num[a])+\" ,\"+str(encode_to_num[b])+\" ,\"+str(prob_per_author[a][b])+\",\"+str(prob_per_author[b][a])+\",\"+str(total)+\",\"+str(addition)+\",\"+str(sqsum)+\" ,\"+str(authors_name[a])+\" ,\"+str(authors_name[b])+\"\\n\")\n",
    "                        \n",
    "                        \n",
    "                        if total in total_prob.keys():\n",
    "                            total_prob[total]+=result\n",
    "                        else:\n",
    "                            total_prob[total]=result\n",
    "                            \n",
    "                        if addition in add_prob.keys():\n",
    "                            add_prob[addition]+=result\n",
    "                        else:\n",
    "                            add_prob[addition]=result\n",
    "                        if sqsum in sq_prob.keys():\n",
    "                            sq_prob[sqsum]+=result\n",
    "                        else:\n",
    "                            sq_prob[sqsum]=result\n",
    "                        \n",
    "            \n",
    "        out.close()\n",
    "        \n",
    "        return total_prob, add_prob, sq_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done  42 out of  42 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "prob_per_author = getProbsGSThread(4, clf, DATA_PCA, y, allAuthors, 'models/', '100-w10-classifier.joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAuthorNames = authors_to_num.keys()\n",
    "total_prob, add_prob, sq_prob = getCombinedProbs(\"results.csv\", prob_per_author, list(allAuthors), encode_to_num, list(allAuthorNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author 1</th>\n",
       "      <th>Author 2</th>\n",
       "      <th>P(1-&gt;2)</th>\n",
       "      <th>P(2-&gt;1)</th>\n",
       "      <th>P(1-&gt;2)*P(2-&gt;1)</th>\n",
       "      <th>(P(1-&gt;2)+P(2-&gt;1))/2</th>\n",
       "      <th>(P(1-&gt;2)^2+P(2-&gt;1)^2)/2</th>\n",
       "      <th>Encode 1</th>\n",
       "      <th>Encode 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>Bleiben Sie sachlich</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>0.055591</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>CETAoderGoodByeGermany</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.044838</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>Eckard P.</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.019613</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>Friwi</td>\n",
       "      <td>0.034246</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ariovistvs</td>\n",
       "      <td>Gamma Ray Burst</td>\n",
       "      <td>0.047202</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.043221</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>too late</td>\n",
       "      <td>whitemouse-neu</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.015186</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>too late</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>0.021733</td>\n",
       "      <td>0.040401</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.031067</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>whitemouse</td>\n",
       "      <td>whitemouse-neu</td>\n",
       "      <td>0.033616</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.021595</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>whitemouse</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>0.038998</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>whitemouse-neu</td>\n",
       "      <td>zelebration</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.048502</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>861 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author 1                 Author 2   P(1->2)   P(2->1)  \\\n",
       "0        Ariovistvs     Bleiben Sie sachlich   0.029295  0.055591   \n",
       "1        Ariovistvs   CETAoderGoodByeGermany   0.021360  0.044838   \n",
       "2        Ariovistvs                Eckard P.   0.010951  0.028275   \n",
       "3        Ariovistvs                    Friwi   0.034246  0.029514   \n",
       "4        Ariovistvs          Gamma Ray Burst   0.047202  0.039241   \n",
       "..               ...                      ...       ...       ...   \n",
       "856        too late           whitemouse-neu   0.019798  0.010574   \n",
       "857        too late              zelebration   0.021733  0.040401   \n",
       "858      whitemouse           whitemouse-neu   0.033616  0.009573   \n",
       "859      whitemouse              zelebration   0.038998  0.009505   \n",
       "860  whitemouse-neu              zelebration   0.010951  0.048502   \n",
       "\n",
       "     P(1->2)*P(2->1)  (P(1->2)+P(2->1))/2   (P(1->2)^2+P(2->1)^2)/2  \\\n",
       "0           0.001629             0.042443                  0.001974   \n",
       "1           0.000958             0.033099                  0.001233   \n",
       "2           0.000310             0.019613                  0.000460   \n",
       "3           0.001011             0.031880                  0.001022   \n",
       "4           0.001852             0.043221                  0.001884   \n",
       "..               ...                  ...                       ...   \n",
       "856         0.000209             0.015186                  0.000252   \n",
       "857         0.000878             0.031067                  0.001052   \n",
       "858         0.000322             0.021595                  0.000611   \n",
       "859         0.000371             0.024251                  0.000806   \n",
       "860         0.000531             0.029727                  0.001236   \n",
       "\n",
       "      Encode 1   Encode 2  \n",
       "0            0          1  \n",
       "1            0          2  \n",
       "2            0          3  \n",
       "3            0          4  \n",
       "4            0          5  \n",
       "..         ...        ...  \n",
       "856         38         40  \n",
       "857         38         41  \n",
       "858         39         40  \n",
       "859         39         41  \n",
       "860         40         41  \n",
       "\n",
       "[861 rows x 9 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('Joined.csv')\n",
    "# enc = data['username']\n",
    "# data['Label'] = label.transform(enc)\n",
    "# data.to_csv('Joined_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = pd.read_csv('Features.csv').drop(['Unnamed: 0'], axis  = 1)\n",
    "# abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dat = pd.read_csv('New__datasets.csv')\n",
    "# datdrop = new_dat.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datdrop\n",
    "# datdrop.join(abc)\n",
    "# joined  = new_dat.join(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
